{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "\n",
    "# Final Project (DATS 6202 - O10), Spring 2019\n",
    "\n",
    "### Earthquake Time Prediction\n",
    "\n",
    "### Data Science, Columbian College of Arts & Sciences, George Washington University\n",
    "\n",
    "### Author: Elie Tetteh-Wayoe, Mihir Gadgil and Poornima Joshi\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem and Motivation:\n",
    "\n",
    "Forecasting earthquakes is one of the most important challenges in Earth science because\n",
    "of their devastating consequences. Current scientific studies related to earthquake\n",
    "forecasting focus on three key points: when the event will occur, where it will occur, and how\n",
    "large it will be. Los Alamos National Laboratory is hosting a [Kaggle competition](https://www.kaggle.com/c/LANL-Earthquake-Prediction) to further\n",
    "this research.\n",
    "\n",
    "In this competition, the aim is to address when the earthquake will take place. Specifically,\n",
    "predict the time remaining before laboratory earthquakes occur from seismic data (the data is generated by an experiment, it isn't actual seismic data).\n",
    "The challenge is that the data has only one feature and target to work with. The\n",
    "`acoustic_data` is the feature and `time_to_failure` is the target. Creating multiple sensible\n",
    "features from the available data will be a core part of the project.\n",
    "\n",
    "If this challenge is solved and the physics are ultimately shown to scale from the laboratory\n",
    "to the field, researchers will have the potential to improve earthquake hazard assessments\n",
    "that could save lives and billions of dollars in infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from os import listdir\n",
    "from os.path import isfile\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Set Pandas precision\n",
    "pd.set_option('display.precision', 9)\n",
    "# matplotlib inline plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train.csv', 'LANL_data.tar.gz', '.gitignore', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "# What kind of data do we have\n",
    "print(os.listdir(\"data/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data looks like this :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acoustic_data</th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>1.469099983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1.469099982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1.469099981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1.469099980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1.469099979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acoustic_data  time_to_failure\n",
       "0             12      1.469099983\n",
       "1              6      1.469099982\n",
       "2              8      1.469099981\n",
       "3              5      1.469099980\n",
       "4              8      1.469099979"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How does the data look like \n",
    "\n",
    "z = pd.read_csv(\"data/train.csv\", nrows=5)\n",
    "print(\"The data looks like this :\")\n",
    "z.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below has been commented out to avoid reading 9 GB data multiple time, for the sole purpose of counting its length. But it can be run to verify the number we have provided.\n",
    "\n",
    "Total number of rows: 629,145,480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at how big our data is\n",
    "\n",
    "# df_length = 0\n",
    "# for training in pd.read_csv('data/train.csv', chunksize=150000):\n",
    "#     df_length = df_length + len(training)\n",
    "    \n",
    "# print(\"Train has: rows: {} \".format(df_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have one long array of seismic data. We will break it down into chunks of size 150,000 (chunk) and each chunk will be one signal in our data. The reasoning is that each segment in the test data has length 150,000. The `time_to_failure` at the last time step of each segment becomes the target associated with that segment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is meant for plotting the data. It is again commented to avoid reading huge amounts of data. It should be uncommented if desired.\n",
    "An image of the plot has been included with the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df_train = pd.DataFrame(columns=['acoustic_data', 'time_to_failure'], dtype=np.float)\n",
    "\n",
    "# for train in pd.read_csv('data/train.csv', chunksize=150000):\n",
    "#     df_train = df_train.append(train[::50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig, ax1 = plt.subplots(figsize=(16, 8))\n",
    "# plt.title(\"Trends of acoustic_data and time_to_failure. 2% of data (sampled)\")\n",
    "# plt.plot(df_train['acoustic_data'], color='b')\n",
    "# ax1.set_ylabel('acoustic_data', color='b')\n",
    "# plt.legend(['acoustic_data'])\n",
    "# ax2 = ax1.twinx()\n",
    "# plt.plot(df_train['time_to_failure'], color='g')\n",
    "# ax2.set_ylabel('time_to_failure', color='g')\n",
    "# plt.legend(['time_to_failure'], loc=(0.875, 0.9))\n",
    "# plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Since the data we use here has only one feature to use for learning and the data set is fairly huge to work with, it is important to capture the essence of the data. Thus, we are generating more features using the exsisting data by using methods like calulating mean, standard deviation, rolling statistics etc.\n",
    "\n",
    "Further, to choose the best features that contribute significantly to model, we build a random forest regressor in order to identify the top contributing features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features from each part of the segment\n",
    "\n",
    "The original long seismic signal has been broken down into several more features. Usually features such as mean, standard deviation, range, percentiles etc are calculated over each part of the chunk and each part of the chunk is represented by its own list of such features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating more features from the existing data\n",
    "n = 150_000\n",
    "freq = 500\n",
    "columns = [\n",
    "    'mean', 'std', 'min', 'max', 'sum', 'abs_mean', 'abs_std', 'abs_max', 'abs_sum', 'argmax', 'rate_mean', 'rate_std',\n",
    "    'rate_max', 'rate_min', 'rate_abs_max'\n",
    "]\n",
    "\n",
    "columns.extend(['fftr' + str(i) for i in range(0, freq)])\n",
    "columns.extend(['fftr' + str(i) for i in range(n//2 - freq, n//2 + freq)])\n",
    "columns.extend(['fftr' + str(i) for i in range(n-freq, n)])\n",
    "columns.extend(['ffti' + str(i) for i in range(0, freq)])\n",
    "columns.extend(['ffti' + str(i) for i in range(n//2 - freq, n//2 + freq)])\n",
    "columns.extend(['ffti' + str(i) for i in range(n-freq, n)])\n",
    "\n",
    "roll_windows = [100, 500, 1000, 2000, 4000, 10000]\n",
    "columns.extend(['rolling_mean_' + str(i) for i in roll_windows])\n",
    "columns.extend(['rolling_std_' + str(i) for i in roll_windows])\n",
    "\n",
    "df_train = pd.DataFrame(dtype=np.float, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(chunk):\n",
    "    mean = chunk['acoustic_data'].mean()\n",
    "    std = chunk['acoustic_data'].std()\n",
    "    min = chunk['acoustic_data'].min()\n",
    "    max = chunk['acoustic_data'].max()\n",
    "    sum = chunk['acoustic_data'].sum()\n",
    "    abs_sum = chunk['acoustic_data'].abs().sum()\n",
    "    abs_max = chunk['acoustic_data'].abs().max()\n",
    "    abs_mean = chunk['acoustic_data'].abs().mean()\n",
    "    abs_std = chunk['acoustic_data'].abs().std()\n",
    "    argmax = chunk['acoustic_data'].abs().values.argmax()\n",
    "    rate = np.diff(chunk['acoustic_data'].values)\n",
    "    rate_mean = rate.mean()\n",
    "    rate_std = rate.std()\n",
    "    rate_max = rate.max()\n",
    "    rate_min = rate.min()\n",
    "    rate_abs_max = np.abs(rate).max()\n",
    "    fft = np.fft.fft(chunk['acoustic_data'], n=n)\n",
    "    result = [\n",
    "        mean, std, min, max, sum, abs_mean, abs_std, abs_max, abs_sum, argmax, rate_mean, rate_std, rate_max, rate_min,\n",
    "        rate_abs_max\n",
    "    ]\n",
    "    result.extend(list(fft.real[0:freq]))\n",
    "    result.extend(list(fft.real[n//2-freq:n//2+freq]))\n",
    "    result.extend(list(fft.real[n-freq:n]))\n",
    "    result.extend(list(fft.imag[0:freq]))\n",
    "    result.extend(list(fft.imag[n//2-freq:n//2+freq]))\n",
    "    result.extend(list(fft.imag[n-freq:n]))\n",
    "    for window in roll_windows:\n",
    "        result.append(\n",
    "            chunk['acoustic_data'].rolling(window=window).mean().mean(skipna=True)\n",
    "        )\n",
    "        result.append(\n",
    "            chunk['acoustic_data'].rolling(window=window).std().mean(skipna=True)\n",
    "        )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for chunk in pd.read_csv('data/train.csv', chunksize=n):\n",
    "    df_train.loc[i, columns] = generate_features(chunk)\n",
    "    df_train.loc[i, 'time_to_failure'] = chunk['time_to_failure'].values[-1]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>sum</th>\n",
       "      <th>abs_mean</th>\n",
       "      <th>abs_std</th>\n",
       "      <th>abs_max</th>\n",
       "      <th>abs_sum</th>\n",
       "      <th>argmax</th>\n",
       "      <th>...</th>\n",
       "      <th>rolling_mean_2000</th>\n",
       "      <th>rolling_mean_4000</th>\n",
       "      <th>rolling_mean_10000</th>\n",
       "      <th>rolling_std_100</th>\n",
       "      <th>rolling_std_500</th>\n",
       "      <th>rolling_std_1000</th>\n",
       "      <th>rolling_std_2000</th>\n",
       "      <th>rolling_std_4000</th>\n",
       "      <th>rolling_std_10000</th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4.195000000e+03</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.519475158</td>\n",
       "      <td>6.547788191</td>\n",
       "      <td>-149.190941597</td>\n",
       "      <td>163.522288439</td>\n",
       "      <td>677807.531823599</td>\n",
       "      <td>5.547366504</td>\n",
       "      <td>5.750164895</td>\n",
       "      <td>170.046245530</td>\n",
       "      <td>8.319850017e+05</td>\n",
       "      <td>75732.748748510</td>\n",
       "      <td>...</td>\n",
       "      <td>4.494530245</td>\n",
       "      <td>4.519455817</td>\n",
       "      <td>4.651122824</td>\n",
       "      <td>4.519434433</td>\n",
       "      <td>4.875305718</td>\n",
       "      <td>4.519406578</td>\n",
       "      <td>5.147596567</td>\n",
       "      <td>4.519440725</td>\n",
       "      <td>5.534768028</td>\n",
       "      <td>5.683670383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.256049486</td>\n",
       "      <td>8.503939490</td>\n",
       "      <td>265.087983548</td>\n",
       "      <td>272.930331447</td>\n",
       "      <td>39087.639872457</td>\n",
       "      <td>1.517037556</td>\n",
       "      <td>8.339211436</td>\n",
       "      <td>296.887014915</td>\n",
       "      <td>2.277461406e+05</td>\n",
       "      <td>43215.786643884</td>\n",
       "      <td>...</td>\n",
       "      <td>2.100400425</td>\n",
       "      <td>0.256133707</td>\n",
       "      <td>2.204306437</td>\n",
       "      <td>0.256222511</td>\n",
       "      <td>2.393564200</td>\n",
       "      <td>0.256388311</td>\n",
       "      <td>2.723462863</td>\n",
       "      <td>0.256914819</td>\n",
       "      <td>3.492272857</td>\n",
       "      <td>3.673246303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.596313333</td>\n",
       "      <td>2.802720142</td>\n",
       "      <td>-5515.000000000</td>\n",
       "      <td>23.000000000</td>\n",
       "      <td>207622.000000000</td>\n",
       "      <td>4.147706667</td>\n",
       "      <td>2.589085218</td>\n",
       "      <td>23.000000000</td>\n",
       "      <td>2.189980000e+05</td>\n",
       "      <td>32.000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.763978830</td>\n",
       "      <td>3.596077322</td>\n",
       "      <td>2.773865037</td>\n",
       "      <td>3.596091178</td>\n",
       "      <td>2.782937017</td>\n",
       "      <td>3.594675703</td>\n",
       "      <td>2.790480525</td>\n",
       "      <td>3.596157421</td>\n",
       "      <td>2.795723461</td>\n",
       "      <td>0.006397657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.349496667</td>\n",
       "      <td>4.478637142</td>\n",
       "      <td>-154.000000000</td>\n",
       "      <td>92.000000000</td>\n",
       "      <td>652414.000000000</td>\n",
       "      <td>5.061843333</td>\n",
       "      <td>3.862810034</td>\n",
       "      <td>94.000000000</td>\n",
       "      <td>7.592765000e+05</td>\n",
       "      <td>38923.000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.608049516</td>\n",
       "      <td>4.349204827</td>\n",
       "      <td>3.692809198</td>\n",
       "      <td>4.349688480</td>\n",
       "      <td>3.822511676</td>\n",
       "      <td>4.350300757</td>\n",
       "      <td>3.969471868</td>\n",
       "      <td>4.350899598</td>\n",
       "      <td>4.154359407</td>\n",
       "      <td>2.635348205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.522146667</td>\n",
       "      <td>5.618797775</td>\n",
       "      <td>-111.000000000</td>\n",
       "      <td>123.000000000</td>\n",
       "      <td>678274.000000000</td>\n",
       "      <td>5.380853333</td>\n",
       "      <td>4.781513433</td>\n",
       "      <td>127.000000000</td>\n",
       "      <td>8.071280000e+05</td>\n",
       "      <td>76146.000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.290168141</td>\n",
       "      <td>4.521862665</td>\n",
       "      <td>4.429379855</td>\n",
       "      <td>4.521381707</td>\n",
       "      <td>4.621979719</td>\n",
       "      <td>4.522010216</td>\n",
       "      <td>4.857082991</td>\n",
       "      <td>4.522608771</td>\n",
       "      <td>5.141857763</td>\n",
       "      <td>5.358795935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.693350000</td>\n",
       "      <td>6.880903553</td>\n",
       "      <td>-79.000000000</td>\n",
       "      <td>170.000000000</td>\n",
       "      <td>704002.500000000</td>\n",
       "      <td>5.748553333</td>\n",
       "      <td>5.887947258</td>\n",
       "      <td>175.000000000</td>\n",
       "      <td>8.622830000e+05</td>\n",
       "      <td>112417.500000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.944028752</td>\n",
       "      <td>4.693063728</td>\n",
       "      <td>5.140581035</td>\n",
       "      <td>4.693345636</td>\n",
       "      <td>5.419183066</td>\n",
       "      <td>4.693747711</td>\n",
       "      <td>5.746768467</td>\n",
       "      <td>4.693672359</td>\n",
       "      <td>6.171136010</td>\n",
       "      <td>8.177499733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.391993333</td>\n",
       "      <td>153.703569356</td>\n",
       "      <td>-15.000000000</td>\n",
       "      <td>5444.000000000</td>\n",
       "      <td>808799.000000000</td>\n",
       "      <td>32.762073333</td>\n",
       "      <td>150.432368254</td>\n",
       "      <td>5515.000000000</td>\n",
       "      <td>4.914311000e+06</td>\n",
       "      <td>149985.000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>40.833016217</td>\n",
       "      <td>5.392530339</td>\n",
       "      <td>42.577828502</td>\n",
       "      <td>5.391952193</td>\n",
       "      <td>46.048275306</td>\n",
       "      <td>5.390577464</td>\n",
       "      <td>52.659806087</td>\n",
       "      <td>5.382573062</td>\n",
       "      <td>68.680476387</td>\n",
       "      <td>16.103195567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 4028 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean             std             min             max  \\\n",
       "count  4195.000000000  4195.000000000  4195.000000000  4195.000000000   \n",
       "mean      4.519475158     6.547788191  -149.190941597   163.522288439   \n",
       "std       0.256049486     8.503939490   265.087983548   272.930331447   \n",
       "min       3.596313333     2.802720142 -5515.000000000    23.000000000   \n",
       "25%       4.349496667     4.478637142  -154.000000000    92.000000000   \n",
       "50%       4.522146667     5.618797775  -111.000000000   123.000000000   \n",
       "75%       4.693350000     6.880903553   -79.000000000   170.000000000   \n",
       "max       5.391993333   153.703569356   -15.000000000  5444.000000000   \n",
       "\n",
       "                    sum        abs_mean         abs_std         abs_max  \\\n",
       "count    4195.000000000  4195.000000000  4195.000000000  4195.000000000   \n",
       "mean   677807.531823599     5.547366504     5.750164895   170.046245530   \n",
       "std     39087.639872457     1.517037556     8.339211436   296.887014915   \n",
       "min    207622.000000000     4.147706667     2.589085218    23.000000000   \n",
       "25%    652414.000000000     5.061843333     3.862810034    94.000000000   \n",
       "50%    678274.000000000     5.380853333     4.781513433   127.000000000   \n",
       "75%    704002.500000000     5.748553333     5.887947258   175.000000000   \n",
       "max    808799.000000000    32.762073333   150.432368254  5515.000000000   \n",
       "\n",
       "               abs_sum            argmax  ...  rolling_mean_2000  \\\n",
       "count  4.195000000e+03    4195.000000000  ...     4195.000000000   \n",
       "mean   8.319850017e+05   75732.748748510  ...        4.494530245   \n",
       "std    2.277461406e+05   43215.786643884  ...        2.100400425   \n",
       "min    2.189980000e+05      32.000000000  ...        2.763978830   \n",
       "25%    7.592765000e+05   38923.000000000  ...        3.608049516   \n",
       "50%    8.071280000e+05   76146.000000000  ...        4.290168141   \n",
       "75%    8.622830000e+05  112417.500000000  ...        4.944028752   \n",
       "max    4.914311000e+06  149985.000000000  ...       40.833016217   \n",
       "\n",
       "       rolling_mean_4000  rolling_mean_10000  rolling_std_100  \\\n",
       "count     4195.000000000      4195.000000000   4195.000000000   \n",
       "mean         4.519455817         4.651122824      4.519434433   \n",
       "std          0.256133707         2.204306437      0.256222511   \n",
       "min          3.596077322         2.773865037      3.596091178   \n",
       "25%          4.349204827         3.692809198      4.349688480   \n",
       "50%          4.521862665         4.429379855      4.521381707   \n",
       "75%          4.693063728         5.140581035      4.693345636   \n",
       "max          5.392530339        42.577828502      5.391952193   \n",
       "\n",
       "       rolling_std_500  rolling_std_1000  rolling_std_2000  rolling_std_4000  \\\n",
       "count   4195.000000000    4195.000000000    4195.000000000    4195.000000000   \n",
       "mean       4.875305718       4.519406578       5.147596567       4.519440725   \n",
       "std        2.393564200       0.256388311       2.723462863       0.256914819   \n",
       "min        2.782937017       3.594675703       2.790480525       3.596157421   \n",
       "25%        3.822511676       4.350300757       3.969471868       4.350899598   \n",
       "50%        4.621979719       4.522010216       4.857082991       4.522608771   \n",
       "75%        5.419183066       4.693747711       5.746768467       4.693672359   \n",
       "max       46.048275306       5.390577464      52.659806087       5.382573062   \n",
       "\n",
       "       rolling_std_10000  time_to_failure  \n",
       "count     4195.000000000   4195.000000000  \n",
       "mean         5.534768028      5.683670383  \n",
       "std          3.492272857      3.673246303  \n",
       "min          2.795723461      0.006397657  \n",
       "25%          4.154359407      2.635348205  \n",
       "50%          5.141857763      5.358795935  \n",
       "75%          6.171136010      8.177499733  \n",
       "max         68.680476387     16.103195567  \n",
       "\n",
       "[8 rows x 4028 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>sum</th>\n",
       "      <th>abs_mean</th>\n",
       "      <th>abs_std</th>\n",
       "      <th>abs_max</th>\n",
       "      <th>abs_sum</th>\n",
       "      <th>argmax</th>\n",
       "      <th>...</th>\n",
       "      <th>rolling_mean_2000</th>\n",
       "      <th>rolling_mean_4000</th>\n",
       "      <th>rolling_mean_10000</th>\n",
       "      <th>rolling_std_100</th>\n",
       "      <th>rolling_std_500</th>\n",
       "      <th>rolling_std_1000</th>\n",
       "      <th>rolling_std_2000</th>\n",
       "      <th>rolling_std_4000</th>\n",
       "      <th>rolling_std_10000</th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.884113333</td>\n",
       "      <td>5.101106131</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>732617.0</td>\n",
       "      <td>5.576566667</td>\n",
       "      <td>4.333324674</td>\n",
       "      <td>104.0</td>\n",
       "      <td>836485.0</td>\n",
       "      <td>2592.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.182269694</td>\n",
       "      <td>4.883418266</td>\n",
       "      <td>4.288590311</td>\n",
       "      <td>4.881665249</td>\n",
       "      <td>4.411259502</td>\n",
       "      <td>4.879250551</td>\n",
       "      <td>4.460670633</td>\n",
       "      <td>4.876886100</td>\n",
       "      <td>4.431413244</td>\n",
       "      <td>1.430797186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.725766667</td>\n",
       "      <td>6.588823782</td>\n",
       "      <td>-154.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>708865.0</td>\n",
       "      <td>5.734166667</td>\n",
       "      <td>5.732776966</td>\n",
       "      <td>181.0</td>\n",
       "      <td>860125.0</td>\n",
       "      <td>11860.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.653421355</td>\n",
       "      <td>4.724876383</td>\n",
       "      <td>4.843485536</td>\n",
       "      <td>4.724689860</td>\n",
       "      <td>5.116232929</td>\n",
       "      <td>4.721938879</td>\n",
       "      <td>5.476469293</td>\n",
       "      <td>4.713898269</td>\n",
       "      <td>6.046480431</td>\n",
       "      <td>1.391498893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.906393333</td>\n",
       "      <td>6.967397034</td>\n",
       "      <td>-106.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>735959.0</td>\n",
       "      <td>6.152646667</td>\n",
       "      <td>5.895944714</td>\n",
       "      <td>140.0</td>\n",
       "      <td>922897.0</td>\n",
       "      <td>129279.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.178792262</td>\n",
       "      <td>4.905839578</td>\n",
       "      <td>5.423012904</td>\n",
       "      <td>4.906173495</td>\n",
       "      <td>5.774157759</td>\n",
       "      <td>4.904014151</td>\n",
       "      <td>6.125550607</td>\n",
       "      <td>4.901086207</td>\n",
       "      <td>6.324556488</td>\n",
       "      <td>1.353196095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.902240000</td>\n",
       "      <td>6.922305187</td>\n",
       "      <td>-199.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>735336.0</td>\n",
       "      <td>5.933960000</td>\n",
       "      <td>6.061213600</td>\n",
       "      <td>199.0</td>\n",
       "      <td>890094.0</td>\n",
       "      <td>67060.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.743548231</td>\n",
       "      <td>4.901486292</td>\n",
       "      <td>4.939280458</td>\n",
       "      <td>4.901312417</td>\n",
       "      <td>5.226714645</td>\n",
       "      <td>4.899401829</td>\n",
       "      <td>5.569334638</td>\n",
       "      <td>4.890118824</td>\n",
       "      <td>6.102269867</td>\n",
       "      <td>1.313797802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.908720000</td>\n",
       "      <td>7.301110190</td>\n",
       "      <td>-126.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>736308.0</td>\n",
       "      <td>6.110586667</td>\n",
       "      <td>6.329485314</td>\n",
       "      <td>145.0</td>\n",
       "      <td>916588.0</td>\n",
       "      <td>80896.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.950485374</td>\n",
       "      <td>4.910195703</td>\n",
       "      <td>5.121868457</td>\n",
       "      <td>4.910102418</td>\n",
       "      <td>5.377340466</td>\n",
       "      <td>4.909516745</td>\n",
       "      <td>5.770087321</td>\n",
       "      <td>4.912307696</td>\n",
       "      <td>6.314026153</td>\n",
       "      <td>1.274399509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4028 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean          std    min    max       sum     abs_mean      abs_std  \\\n",
       "0  4.884113333  5.101106131  -98.0  104.0  732617.0  5.576566667  4.333324674   \n",
       "1  4.725766667  6.588823782 -154.0  181.0  708865.0  5.734166667  5.732776966   \n",
       "2  4.906393333  6.967397034 -106.0  140.0  735959.0  6.152646667  5.895944714   \n",
       "3  4.902240000  6.922305187 -199.0  197.0  735336.0  5.933960000  6.061213600   \n",
       "4  4.908720000  7.301110190 -126.0  145.0  736308.0  6.110586667  6.329485314   \n",
       "\n",
       "   abs_max   abs_sum    argmax  ...  rolling_mean_2000  rolling_mean_4000  \\\n",
       "0    104.0  836485.0    2592.0  ...        4.182269694        4.883418266   \n",
       "1    181.0  860125.0   11860.0  ...        4.653421355        4.724876383   \n",
       "2    140.0  922897.0  129279.0  ...        5.178792262        4.905839578   \n",
       "3    199.0  890094.0   67060.0  ...        4.743548231        4.901486292   \n",
       "4    145.0  916588.0   80896.0  ...        4.950485374        4.910195703   \n",
       "\n",
       "   rolling_mean_10000  rolling_std_100  rolling_std_500  rolling_std_1000  \\\n",
       "0         4.288590311      4.881665249      4.411259502       4.879250551   \n",
       "1         4.843485536      4.724689860      5.116232929       4.721938879   \n",
       "2         5.423012904      4.906173495      5.774157759       4.904014151   \n",
       "3         4.939280458      4.901312417      5.226714645       4.899401829   \n",
       "4         5.121868457      4.910102418      5.377340466       4.909516745   \n",
       "\n",
       "   rolling_std_2000  rolling_std_4000  rolling_std_10000  time_to_failure  \n",
       "0       4.460670633       4.876886100        4.431413244      1.430797186  \n",
       "1       5.476469293       4.713898269        6.046480431      1.391498893  \n",
       "2       6.125550607       4.901086207        6.324556488      1.353196095  \n",
       "3       5.569334638       4.890118824        6.102269867      1.313797802  \n",
       "4       5.770087321       4.912307696        6.314026153      1.274399509  \n",
       "\n",
       "[5 rows x 4028 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if any nan values are generated\n",
    "df_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the data into X_train and Y_train\n",
    "\n",
    "X_train = df_train.drop(columns=['time_to_failure']).values\n",
    "y_train = df_train['time_to_failure'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing the best contributing features using random forest regressor\n",
    "rfr = RandomForestRegressor(n_estimators=100, random_state=0, max_features='sqrt', n_jobs=-1)\n",
    "pipe_rfr = Pipeline([('StandardScaler', StandardScaler()), ('RandomForestRegressor', rfr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('StandardScaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('RandomForestRegressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='sqrt', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling fit on the random forest regressor\n",
    "pipe_rfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe to choose the best features\n",
    "features = pd.DataFrame({'Feature': columns, 'Importance': rfr.feature_importances_, 'Correlation': df_train.drop(columns='time_to_failure').corrwith(df_train['time_to_failure']).abs().values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4016</th>\n",
       "      <td>rolling_mean_500</td>\n",
       "      <td>0.046547011</td>\n",
       "      <td>0.342833017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4020</th>\n",
       "      <td>rolling_mean_10000</td>\n",
       "      <td>0.035402002</td>\n",
       "      <td>0.358516850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rate_std</td>\n",
       "      <td>0.023847040</td>\n",
       "      <td>0.184376548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4024</th>\n",
       "      <td>rolling_std_2000</td>\n",
       "      <td>0.023176385</td>\n",
       "      <td>0.356685719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4018</th>\n",
       "      <td>rolling_mean_2000</td>\n",
       "      <td>0.021951967</td>\n",
       "      <td>0.351513349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Feature   Importance  Correlation\n",
       "4016    rolling_mean_500  0.046547011  0.342833017\n",
       "4020  rolling_mean_10000  0.035402002  0.358516850\n",
       "11              rate_std  0.023847040  0.184376548\n",
       "4024    rolling_std_2000  0.023176385  0.356685719\n",
       "4018   rolling_mean_2000  0.021951967  0.351513349"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorting the features in descending order so we choose the best one\n",
    "features = features.sort_values(by='Importance', ascending=False)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the best performing feature from the 'features' dataframe\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.barh(y='Feature', width='Importance', data=features[:30])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting the top 27 features\n",
    "n_features = 30\n",
    "X_train = df_train[features['Feature'][:n_features]].values\n",
    "y_train = df_train['time_to_failure'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression \n",
    "We started with simple linear regression, since that is the simplest and most straight forward method we are familiar with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare pipeline\n",
    "\n",
    "pipe_linear = Pipeline([('StandardScaler', StandardScaler()), ('Linear', linear_model.LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamters for the linear model\n",
    "\n",
    "parameters_linear = [{\n",
    "    'Linear__fit_intercept': ('True', 'False'),\n",
    "    'Linear__normalize': ('True', 'False'),\n",
    "    'Linear__copy_X': ('True', 'False')\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.3628022899776268\n",
      "Best hyperparameters: {'Linear__copy_X': 'True', 'Linear__fit_intercept': 'True', 'Linear__normalize': 'True'}\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search CV on with different parameters\n",
    "\n",
    "gs_linear = GridSearchCV(\n",
    "    estimator=pipe_linear,\n",
    "    param_grid=parameters_linear,\n",
    "    iid=False,\n",
    "    n_jobs=-1,\n",
    "    cv = KFold(\n",
    "        n_splits=10,\n",
    "        shuffle=True,\n",
    "        random_state=0\n",
    "    )\n",
    ")\n",
    "\n",
    "gs_linear.fit(X_train, y_train)\n",
    "print('Best score:', gs_linear.best_score_)\n",
    "print('Best hyperparameters:', gs_linear.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elastic Net\n",
    "To improve the Linear regression results, we used a penalised method like Elastic search. As we can notice, we got slightly better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare pipeline\n",
    "\n",
    "pipe_elastic = Pipeline([('StandardScaler', StandardScaler()), ('ElasticNet', ElasticNet(random_state=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamters for the elasticnet model\n",
    "\n",
    "param_grid_elastic = [{\n",
    "    'ElasticNet__max_iter': [1, 5, 10],\n",
    "    'ElasticNet__alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'ElasticNet__l1_ratio': np.arange(0.0, 1.0, 0.1)\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.29442150801696115\n",
      "Best hyperparameters: {'ElasticNet__alpha': 0.1, 'ElasticNet__l1_ratio': 0.0, 'ElasticNet__max_iter': 10}\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search CV on with different parameters\n",
    "gs_elastic = GridSearchCV(\n",
    "    estimator=pipe_elastic,\n",
    "    param_grid=param_grid_elastic,\n",
    "    iid=False,\n",
    "    n_jobs=-1,\n",
    "    cv = KFold(\n",
    "        n_splits=10,\n",
    "        shuffle=True,\n",
    "        random_state=0\n",
    "    )\n",
    ")\n",
    "\n",
    "gs_elastic.fit(X_train, y_train)\n",
    "print('Best score:', gs_elastic.best_score_)\n",
    "print('Best hyperparameters:', gs_elastic.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next model we are trying is neural network. Earthquakes are a complicated phenomenon, so we expect a neural network to be better at capturing the non-linearity and perform better than linear regression.\n",
    "\n",
    "We are using the top 27 features ranked by importance, so we search through a grid of different hidden layer numbers and sizes. The other hyperparameters being tuned are the learning rate, regularization parameter and the tolerance for cross validation score stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Pipeline\n",
    "\n",
    "pipe_nn = Pipeline([('StandardScaler', StandardScaler()), ('Regressor', MLPRegressor(random_state=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamters for the neural network model\n",
    "\n",
    "param_grid_nn = [{\n",
    "    'Regressor__hidden_layer_sizes': [\n",
    "        (int(n_features*2/3)),\n",
    "        (int(n_features*2/3), int(int(n_features*2/3)*2/3)),\n",
    "        (int(n_features*2/3), int(int(n_features*2/3)*2/3), int(int(int(n_features*2/3)*2/3)*2/3))],\n",
    "    'Regressor__alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'Regressor__learning_rate_init': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'Regressor__tol': [0.0001, 0.001, 0.01]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.4290547540363237\n",
      "Best hyperparameters: {'Regressor__alpha': 0.0001, 'Regressor__hidden_layer_sizes': 20, 'Regressor__learning_rate_init': 0.1, 'Regressor__tol': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search CV on with different parameters\n",
    "\n",
    "gs_nn = GridSearchCV(\n",
    "    estimator=pipe_nn,\n",
    "    param_grid=param_grid_nn,\n",
    "    iid=False,\n",
    "    n_jobs=-1,\n",
    "    cv = KFold(\n",
    "        n_splits=10,\n",
    "        shuffle=True,\n",
    "        random_state=0\n",
    "    )\n",
    ")\n",
    "\n",
    "gs_nn.fit(X_train, y_train)\n",
    "print('Best score:', gs_nn.best_score_)\n",
    "print('Best hyperparameters:', gs_nn.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network using tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function returning a compiled network\n",
    "def kerasModel(optimizer, metrics, loss, activation, input_shape= X_train.shape[1]):\n",
    "    \n",
    "    # Start neural network\n",
    "    network = models.Sequential()\n",
    "\n",
    "    # Add fully connected layer with a ReLU activation function\n",
    "    network.add(layers.Dense(units=input_shape, activation=activation, input_dim=input_shape))\n",
    "\n",
    "    # Add fully connected layer with a ReLU activation function\n",
    "    network.add(layers.Dense(units= int(input_shape/2), activation=activation))\n",
    "\n",
    "    # Add fully connected layer with a sigmoid activation function\n",
    "    network.add(layers.Dense(units=1))\n",
    "\n",
    "    # Compile neural network\n",
    "    network.compile(loss=loss, # Cross-entropy\n",
    "                    optimizer=optimizer, # Optimizer\n",
    "                    metrics=[metrics]) # Accuracy performance metric\n",
    "    \n",
    "    # Return compiled network\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "KModel = KerasRegressor(build_fn=kerasModel, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hyperparameter space\n",
    "epochs = [50 , 100]\n",
    "batches = [50, 100]\n",
    "optimizer = ['adam','sgd']\n",
    "loss = ['mse']\n",
    "activation = ['relu', 'exponential']\n",
    "metrics = ['mse']\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(Model__optimizer=optimizer, Model__loss = loss, Model__epochs=epochs, Model__batch_size=batches, Model__activation= activation,\n",
    "                            Model__metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_keras = Pipeline([('StandardScaler', StandardScaler()), ('Model', KModel)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -7.606178614996769\n",
      "Best hyperparameters: {'Model__activation': 'relu', 'Model__batch_size': 50, 'Model__epochs': 100, 'Model__loss': 'mse', 'Model__metrics': 'mse', 'Model__optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "gs_keras = GridSearchCV(\n",
    "    estimator=pipe_keras,\n",
    "    param_grid=hyperparameters,\n",
    "    iid = False,\n",
    "    n_jobs=-1,\n",
    "    cv = KFold(\n",
    "        n_splits=10,\n",
    "        shuffle=True,\n",
    "        random_state=0\n",
    "    )\n",
    ")\n",
    "\n",
    "gs_keras.fit(X_train, y_train)\n",
    "print('Best score:', gs_keras.best_score_)\n",
    "print('Best hyperparameters:', gs_keras.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traverse through the test directory\n",
    "path = 'data/test/'\n",
    "files = [f[:-4] for f in listdir(path) if isfile(path + f) and f[-3:] == 'csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a submission dataframe\n",
    "\n",
    "predictions = pd.DataFrame(index=files, dtype=np.float, columns=['time_to_failure'])\n",
    "predictions.index.name = 'seg_id'\n",
    "predictions_Keras = pd.DataFrame(index=files, dtype=np.float, columns=['time_to_failure'])\n",
    "predictions_Keras.index.name = 'seg_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all files in the test folder, run predict function and add to 'predictions' dataframe\n",
    "\n",
    "for f in files:\n",
    "    df = pd.read_csv(path+f+'.csv')\n",
    "    df_test = pd.DataFrame(np.array(generate_features(df)).reshape(1,-1), columns=columns)\n",
    "    X_test = df_test[features['Feature'][:n_features]].values\n",
    "    y = gs_keras.predict(X_test)\n",
    "    predictions_Keras.loc[f, 'time_to_failure'] = y\n",
    "    y = gs_nn.predict(X_test)[0]\n",
    "    predictions.loc[f, 'time_to_failure'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>seg_5fe414</th>\n",
       "      <td>3.935923338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_3661de</th>\n",
       "      <td>8.136058807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_5ef47e</th>\n",
       "      <td>6.524250984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_58e9f9</th>\n",
       "      <td>9.525296211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_afd665</th>\n",
       "      <td>5.137159348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            time_to_failure\n",
       "seg_id                     \n",
       "seg_5fe414      3.935923338\n",
       "seg_3661de      8.136058807\n",
       "seg_5ef47e      6.524250984\n",
       "seg_58e9f9      9.525296211\n",
       "seg_afd665      5.137159348"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peek at the predictions\n",
    "\n",
    "predictions_Keras.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>seg_5fe414</th>\n",
       "      <td>4.098522144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_3661de</th>\n",
       "      <td>8.989209750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_5ef47e</th>\n",
       "      <td>6.419899416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_58e9f9</th>\n",
       "      <td>9.394043900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_afd665</th>\n",
       "      <td>5.350356048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            time_to_failure\n",
       "seg_id                     \n",
       "seg_5fe414      4.098522144\n",
       "seg_3661de      8.989209750\n",
       "seg_5ef47e      6.419899416\n",
       "seg_58e9f9      9.394043900\n",
       "seg_afd665      5.350356048"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the predictions dataframe to a csv\n",
    "\n",
    "predictions_Keras.to_csv('submission_Keras.csv')\n",
    "predictions.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Best Parameter | Best Score |\n",
    "|:--- |:--- | ---:|\n",
    "| Linear Regression | 'Linear__copy_X': 'True', 'Linear__fit_intercept': 'True', 'Linear__normalize': 'True' | 0.277 |\n",
    "| Elastic Net | 'ElasticNet__alpha': 0.01, 'ElasticNet__l1_ratio': 0.9, 'ElasticNet__max_iter': 10 | 0.328 |\n",
    "| Neural Network | 'Regressor__alpha': 0.1, 'Regressor__hidden_layer_sizes': 20, 'Regressor__learning_rate_init': 0.01, 'Regressor__tol': 0.0001 | 0.444 |\n",
    "| Neural Network (Using Keras)| 'Model__activation': 'relu', 'Model__batch_size': 50, 'Model__epochs': 100, 'Model__loss': 'mse', 'Model__metrics': 'mse', 'Model__optimizer': 'adam' | 7.606 (MSE) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the cross validation score, we expect Neural Network with 1 input layer, 1 hidden layer with 18 nodes and 1 output layer to give us the best R<sup>2</sup> coefficient. \n",
    "\n",
    "Another important observation we can make in this experiment is that, the performance of the model is higly correlated with the features used. As we can see in the graph, rolling_mean_500 has an importance value of 0.41, followed by  rolling_mean_2000 with an importance value of 0.01. We can see a strike difference in the performance of the features.\n",
    "\n",
    "In conclusion, Neural Network is the best model for this data. More importantly, efficient feature engineering is the key to building a good model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- https://kaggle.com/c/LANL-Earthquake-Prediction/discussion\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\n",
    "- https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
