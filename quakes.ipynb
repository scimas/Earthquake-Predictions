{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "\n",
    "# Final Project (DATS 6202 - O10), Spring 2019\n",
    "\n",
    "### Earthquake Time Prediction\n",
    "\n",
    "### Data Science, Columbian College of Arts & Sciences, George Washington University\n",
    "\n",
    "### Author: Elie Tetteh-Wayoe, Mihir Gadgil and Poornima Joshi\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem and Motivation:\n",
    "\n",
    "Forecasting earthquakes is one of the most important challenges in Earth science because\n",
    "of their devastating consequences. Current scientific studies related to earthquake\n",
    "forecasting focus on three key points: when the event will occur, where it will occur, and how\n",
    "large it will be. Los Alamos National Laboratory is hosting a [Kaggle competition](https://www.kaggle.com/c/LANL-Earthquake-Prediction) to further\n",
    "this research.\n",
    "\n",
    "In this competition, the aim is to address when the earthquake will take place. Specifically,\n",
    "predict the time remaining before laboratory earthquakes occur from seismic data (the data is generated by an experiment, it isn't actual seismic data).\n",
    "The challenge is that the data has only one feature and target to work with. The\n",
    "`acoustic_data` is the feature and `time_to_failure` is the target. Creating multiple sensible\n",
    "features from the available data will be a core part of the project.\n",
    "\n",
    "If this challenge is solved and the physics are ultimately shown to scale from the laboratory\n",
    "to the field, researchers will have the potential to improve earthquake hazard assessments\n",
    "that could save lives and billions of dollars in infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from os import listdir\n",
    "from os.path import isfile\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Set Pandas precision\n",
    "pd.set_option('display.precision', 9)\n",
    "# matplotlib inline plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train.csv', '.gitignore', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "# What kind of data do we have\n",
    "print(os.listdir(\"data/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data looks like this :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acoustic_data</th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>1.469099983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1.469099982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1.469099981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1.469099980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1.469099979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acoustic_data  time_to_failure\n",
       "0             12      1.469099983\n",
       "1              6      1.469099982\n",
       "2              8      1.469099981\n",
       "3              5      1.469099980\n",
       "4              8      1.469099979"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How does the data look like \n",
    "\n",
    "z = pd.read_csv(\"data/train.csv\", nrows=5)\n",
    "print(\"The data looks like this :\")\n",
    "z.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below has been commented out to avoid reading 9 GB data multiple time, for the sole purpose of counting its length. But it can be run to verify the number we have provided.\n",
    "\n",
    "Total number of rows: 629,145,480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at how big our data is\n",
    "\n",
    "# df_length = 0\n",
    "# for training in pd.read_csv('data/train.csv', chunksize=150000):\n",
    "#     df_length = df_length + len(training)\n",
    "    \n",
    "# print(\"Train has: rows: {} \".format(df_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have one long array of seismic data. We will break it down into chunks of size 150,000 (chunk) and each chunk will be one signal in our data. The reasoning is that each segment in the test data has length 150,000. The `time_to_failure` at the last time step of each segment becomes the target associated with that segment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is meant for plotting the data. It is again commented to avoid reading huge amounts of data. It should be uncommented if desired.\n",
    "An image of the plot has been included with the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df_train = pd.DataFrame(columns=['acoustic_data', 'time_to_failure'], dtype=np.float)\n",
    "\n",
    "# for train in pd.read_csv('data/train.csv', chunksize=150000):\n",
    "#     df_train = df_train.append(train[::50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig, ax1 = plt.subplots(figsize=(16, 8))\n",
    "# plt.title(\"Trends of acoustic_data and time_to_failure. 2% of data (sampled)\")\n",
    "# plt.plot(df_train['acoustic_data'], color='b')\n",
    "# ax1.set_ylabel('acoustic_data', color='b')\n",
    "# plt.legend(['acoustic_data'])\n",
    "# ax2 = ax1.twinx()\n",
    "# plt.plot(df_train['time_to_failure'], color='g')\n",
    "# ax2.set_ylabel('time_to_failure', color='g')\n",
    "# plt.legend(['time_to_failure'], loc=(0.875, 0.9))\n",
    "# plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Since the data we use here has only one feature to use for learning and the data set is fairly huge to work with, it is important to capture the essence of the data. Thus, we are generating more features using the exsisting data by using methods like calulating mean, standard deviation, rolling statistics etc.\n",
    "\n",
    "Further, to choose the best features that contribute significantly to model, we build a random forest regressor in order to identify the top contributing features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features from each part of the segment\n",
    "\n",
    "The original long seismic signal has been broken down into several more features. Usually features such as mean, standard deviation, range, percentiles etc are calculated over each part of the chunk and each part of the chunk is represented by its own list of such features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating more features from the existing data\n",
    "n = 150_000\n",
    "freq = 500\n",
    "columns = [\n",
    "    'mean', 'std', 'min', 'max', 'sum', 'abs_mean', 'abs_std', 'abs_max', 'abs_sum', 'argmax', 'rate_mean', 'rate_std',\n",
    "    'rate_max', 'rate_min', 'rate_abs_max'\n",
    "]\n",
    "\n",
    "columns.extend(['fftr' + str(i) for i in range(0, freq)])\n",
    "columns.extend(['fftr' + str(i) for i in range(n//2 - freq, n//2 + freq)])\n",
    "columns.extend(['fftr' + str(i) for i in range(n-freq, n)])\n",
    "columns.extend(['ffti' + str(i) for i in range(0, freq)])\n",
    "columns.extend(['ffti' + str(i) for i in range(n//2 - freq, n//2 + freq)])\n",
    "columns.extend(['ffti' + str(i) for i in range(n-freq, n)])\n",
    "\n",
    "roll_windows = [100, 500, 1000, 2000, 4000, 10000]\n",
    "columns.extend(['rolling_mean_' + str(i) for i in roll_windows])\n",
    "columns.extend(['rolling_std_' + str(i) for i in roll_windows])\n",
    "\n",
    "df_train = pd.DataFrame(dtype=np.float, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(chunk):\n",
    "    mean = chunk['acoustic_data'].mean()\n",
    "    std = chunk['acoustic_data'].std()\n",
    "    min = chunk['acoustic_data'].min()\n",
    "    max = chunk['acoustic_data'].max()\n",
    "    sum = chunk['acoustic_data'].sum()\n",
    "    abs_sum = chunk['acoustic_data'].abs().sum()\n",
    "    abs_max = chunk['acoustic_data'].abs().max()\n",
    "    abs_mean = chunk['acoustic_data'].abs().mean()\n",
    "    abs_std = chunk['acoustic_data'].abs().std()\n",
    "    argmax = chunk['acoustic_data'].abs().values.argmax()\n",
    "    rate = np.diff(chunk['acoustic_data'].values)\n",
    "    rate_mean = rate.mean()\n",
    "    rate_std = rate.std()\n",
    "    rate_max = rate.max()\n",
    "    rate_min = rate.min()\n",
    "    rate_abs_max = np.abs(rate).max()\n",
    "    fft = np.fft.fft(chunk['acoustic_data'], n=n)\n",
    "    result = [\n",
    "        mean, std, min, max, sum, abs_mean, abs_std, abs_max, abs_sum, argmax, rate_mean, rate_std, rate_max, rate_min,\n",
    "        rate_abs_max\n",
    "    ]\n",
    "    result.extend(list(fft.real[0:freq]))\n",
    "    result.extend(list(fft.real[n//2-freq:n//2+freq]))\n",
    "    result.extend(list(fft.real[n-freq:n]))\n",
    "    result.extend(list(fft.imag[0:freq]))\n",
    "    result.extend(list(fft.imag[n//2-freq:n//2+freq]))\n",
    "    result.extend(list(fft.imag[n-freq:n]))\n",
    "    for window in roll_windows:\n",
    "        result.append(\n",
    "            chunk['acoustic_data'].rolling(window=window).mean().mean(skipna=True)\n",
    "        )\n",
    "        result.append(\n",
    "            chunk['acoustic_data'].rolling(window=window).std().mean(skipna=True)\n",
    "        )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for chunk in pd.read_csv('data/train.csv', chunksize=n):\n",
    "    df_train.loc[i, columns] = generate_features(chunk)\n",
    "    df_train.loc[i, 'time_to_failure'] = chunk['time_to_failure'].values[-1]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>sum</th>\n",
       "      <th>abs_mean</th>\n",
       "      <th>abs_std</th>\n",
       "      <th>abs_max</th>\n",
       "      <th>abs_sum</th>\n",
       "      <th>argmax</th>\n",
       "      <th>...</th>\n",
       "      <th>rolling_mean_2000</th>\n",
       "      <th>rolling_mean_4000</th>\n",
       "      <th>rolling_mean_10000</th>\n",
       "      <th>rolling_std_100</th>\n",
       "      <th>rolling_std_500</th>\n",
       "      <th>rolling_std_1000</th>\n",
       "      <th>rolling_std_2000</th>\n",
       "      <th>rolling_std_4000</th>\n",
       "      <th>rolling_std_10000</th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4.195000000e+03</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "      <td>4195.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.519475158</td>\n",
       "      <td>6.547788191</td>\n",
       "      <td>-149.190941597</td>\n",
       "      <td>163.522288439</td>\n",
       "      <td>677807.531823599</td>\n",
       "      <td>5.547366504</td>\n",
       "      <td>5.750164895</td>\n",
       "      <td>170.046245530</td>\n",
       "      <td>8.319850017e+05</td>\n",
       "      <td>75732.748748510</td>\n",
       "      <td>...</td>\n",
       "      <td>4.494530245</td>\n",
       "      <td>4.519455817</td>\n",
       "      <td>4.651122824</td>\n",
       "      <td>4.519434433</td>\n",
       "      <td>4.875305718</td>\n",
       "      <td>4.519406578</td>\n",
       "      <td>5.147596567</td>\n",
       "      <td>4.519440725</td>\n",
       "      <td>5.534768028</td>\n",
       "      <td>5.683670383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.256049486</td>\n",
       "      <td>8.503939490</td>\n",
       "      <td>265.087983548</td>\n",
       "      <td>272.930331447</td>\n",
       "      <td>39087.639872457</td>\n",
       "      <td>1.517037556</td>\n",
       "      <td>8.339211436</td>\n",
       "      <td>296.887014915</td>\n",
       "      <td>2.277461406e+05</td>\n",
       "      <td>43215.786643884</td>\n",
       "      <td>...</td>\n",
       "      <td>2.100400425</td>\n",
       "      <td>0.256133707</td>\n",
       "      <td>2.204306437</td>\n",
       "      <td>0.256222511</td>\n",
       "      <td>2.393564200</td>\n",
       "      <td>0.256388311</td>\n",
       "      <td>2.723462863</td>\n",
       "      <td>0.256914819</td>\n",
       "      <td>3.492272857</td>\n",
       "      <td>3.673246303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.596313333</td>\n",
       "      <td>2.802720142</td>\n",
       "      <td>-5515.000000000</td>\n",
       "      <td>23.000000000</td>\n",
       "      <td>207622.000000000</td>\n",
       "      <td>4.147706667</td>\n",
       "      <td>2.589085218</td>\n",
       "      <td>23.000000000</td>\n",
       "      <td>2.189980000e+05</td>\n",
       "      <td>32.000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.763978830</td>\n",
       "      <td>3.596077322</td>\n",
       "      <td>2.773865037</td>\n",
       "      <td>3.596091178</td>\n",
       "      <td>2.782937017</td>\n",
       "      <td>3.594675703</td>\n",
       "      <td>2.790480525</td>\n",
       "      <td>3.596157421</td>\n",
       "      <td>2.795723461</td>\n",
       "      <td>0.006397657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.349496667</td>\n",
       "      <td>4.478637142</td>\n",
       "      <td>-154.000000000</td>\n",
       "      <td>92.000000000</td>\n",
       "      <td>652414.000000000</td>\n",
       "      <td>5.061843333</td>\n",
       "      <td>3.862810034</td>\n",
       "      <td>94.000000000</td>\n",
       "      <td>7.592765000e+05</td>\n",
       "      <td>38923.000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.608049516</td>\n",
       "      <td>4.349204827</td>\n",
       "      <td>3.692809198</td>\n",
       "      <td>4.349688480</td>\n",
       "      <td>3.822511676</td>\n",
       "      <td>4.350300757</td>\n",
       "      <td>3.969471868</td>\n",
       "      <td>4.350899598</td>\n",
       "      <td>4.154359407</td>\n",
       "      <td>2.635348205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.522146667</td>\n",
       "      <td>5.618797775</td>\n",
       "      <td>-111.000000000</td>\n",
       "      <td>123.000000000</td>\n",
       "      <td>678274.000000000</td>\n",
       "      <td>5.380853333</td>\n",
       "      <td>4.781513433</td>\n",
       "      <td>127.000000000</td>\n",
       "      <td>8.071280000e+05</td>\n",
       "      <td>76146.000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.290168141</td>\n",
       "      <td>4.521862665</td>\n",
       "      <td>4.429379855</td>\n",
       "      <td>4.521381707</td>\n",
       "      <td>4.621979719</td>\n",
       "      <td>4.522010216</td>\n",
       "      <td>4.857082991</td>\n",
       "      <td>4.522608771</td>\n",
       "      <td>5.141857763</td>\n",
       "      <td>5.358795935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.693350000</td>\n",
       "      <td>6.880903553</td>\n",
       "      <td>-79.000000000</td>\n",
       "      <td>170.000000000</td>\n",
       "      <td>704002.500000000</td>\n",
       "      <td>5.748553333</td>\n",
       "      <td>5.887947258</td>\n",
       "      <td>175.000000000</td>\n",
       "      <td>8.622830000e+05</td>\n",
       "      <td>112417.500000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.944028752</td>\n",
       "      <td>4.693063728</td>\n",
       "      <td>5.140581035</td>\n",
       "      <td>4.693345636</td>\n",
       "      <td>5.419183066</td>\n",
       "      <td>4.693747711</td>\n",
       "      <td>5.746768467</td>\n",
       "      <td>4.693672359</td>\n",
       "      <td>6.171136010</td>\n",
       "      <td>8.177499733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.391993333</td>\n",
       "      <td>153.703569356</td>\n",
       "      <td>-15.000000000</td>\n",
       "      <td>5444.000000000</td>\n",
       "      <td>808799.000000000</td>\n",
       "      <td>32.762073333</td>\n",
       "      <td>150.432368254</td>\n",
       "      <td>5515.000000000</td>\n",
       "      <td>4.914311000e+06</td>\n",
       "      <td>149985.000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>40.833016217</td>\n",
       "      <td>5.392530339</td>\n",
       "      <td>42.577828502</td>\n",
       "      <td>5.391952193</td>\n",
       "      <td>46.048275306</td>\n",
       "      <td>5.390577464</td>\n",
       "      <td>52.659806087</td>\n",
       "      <td>5.382573062</td>\n",
       "      <td>68.680476387</td>\n",
       "      <td>16.103195567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 4028 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean             std             min             max  \\\n",
       "count  4195.000000000  4195.000000000  4195.000000000  4195.000000000   \n",
       "mean      4.519475158     6.547788191  -149.190941597   163.522288439   \n",
       "std       0.256049486     8.503939490   265.087983548   272.930331447   \n",
       "min       3.596313333     2.802720142 -5515.000000000    23.000000000   \n",
       "25%       4.349496667     4.478637142  -154.000000000    92.000000000   \n",
       "50%       4.522146667     5.618797775  -111.000000000   123.000000000   \n",
       "75%       4.693350000     6.880903553   -79.000000000   170.000000000   \n",
       "max       5.391993333   153.703569356   -15.000000000  5444.000000000   \n",
       "\n",
       "                    sum        abs_mean         abs_std         abs_max  \\\n",
       "count    4195.000000000  4195.000000000  4195.000000000  4195.000000000   \n",
       "mean   677807.531823599     5.547366504     5.750164895   170.046245530   \n",
       "std     39087.639872457     1.517037556     8.339211436   296.887014915   \n",
       "min    207622.000000000     4.147706667     2.589085218    23.000000000   \n",
       "25%    652414.000000000     5.061843333     3.862810034    94.000000000   \n",
       "50%    678274.000000000     5.380853333     4.781513433   127.000000000   \n",
       "75%    704002.500000000     5.748553333     5.887947258   175.000000000   \n",
       "max    808799.000000000    32.762073333   150.432368254  5515.000000000   \n",
       "\n",
       "               abs_sum            argmax  ...  rolling_mean_2000  \\\n",
       "count  4.195000000e+03    4195.000000000  ...     4195.000000000   \n",
       "mean   8.319850017e+05   75732.748748510  ...        4.494530245   \n",
       "std    2.277461406e+05   43215.786643884  ...        2.100400425   \n",
       "min    2.189980000e+05      32.000000000  ...        2.763978830   \n",
       "25%    7.592765000e+05   38923.000000000  ...        3.608049516   \n",
       "50%    8.071280000e+05   76146.000000000  ...        4.290168141   \n",
       "75%    8.622830000e+05  112417.500000000  ...        4.944028752   \n",
       "max    4.914311000e+06  149985.000000000  ...       40.833016217   \n",
       "\n",
       "       rolling_mean_4000  rolling_mean_10000  rolling_std_100  \\\n",
       "count     4195.000000000      4195.000000000   4195.000000000   \n",
       "mean         4.519455817         4.651122824      4.519434433   \n",
       "std          0.256133707         2.204306437      0.256222511   \n",
       "min          3.596077322         2.773865037      3.596091178   \n",
       "25%          4.349204827         3.692809198      4.349688480   \n",
       "50%          4.521862665         4.429379855      4.521381707   \n",
       "75%          4.693063728         5.140581035      4.693345636   \n",
       "max          5.392530339        42.577828502      5.391952193   \n",
       "\n",
       "       rolling_std_500  rolling_std_1000  rolling_std_2000  rolling_std_4000  \\\n",
       "count   4195.000000000    4195.000000000    4195.000000000    4195.000000000   \n",
       "mean       4.875305718       4.519406578       5.147596567       4.519440725   \n",
       "std        2.393564200       0.256388311       2.723462863       0.256914819   \n",
       "min        2.782937017       3.594675703       2.790480525       3.596157421   \n",
       "25%        3.822511676       4.350300757       3.969471868       4.350899598   \n",
       "50%        4.621979719       4.522010216       4.857082991       4.522608771   \n",
       "75%        5.419183066       4.693747711       5.746768467       4.693672359   \n",
       "max       46.048275306       5.390577464      52.659806087       5.382573062   \n",
       "\n",
       "       rolling_std_10000  time_to_failure  \n",
       "count     4195.000000000   4195.000000000  \n",
       "mean         5.534768028      5.683670383  \n",
       "std          3.492272857      3.673246303  \n",
       "min          2.795723461      0.006397657  \n",
       "25%          4.154359407      2.635348205  \n",
       "50%          5.141857763      5.358795935  \n",
       "75%          6.171136010      8.177499733  \n",
       "max         68.680476387     16.103195567  \n",
       "\n",
       "[8 rows x 4028 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>sum</th>\n",
       "      <th>abs_mean</th>\n",
       "      <th>abs_std</th>\n",
       "      <th>abs_max</th>\n",
       "      <th>abs_sum</th>\n",
       "      <th>argmax</th>\n",
       "      <th>...</th>\n",
       "      <th>rolling_mean_2000</th>\n",
       "      <th>rolling_mean_4000</th>\n",
       "      <th>rolling_mean_10000</th>\n",
       "      <th>rolling_std_100</th>\n",
       "      <th>rolling_std_500</th>\n",
       "      <th>rolling_std_1000</th>\n",
       "      <th>rolling_std_2000</th>\n",
       "      <th>rolling_std_4000</th>\n",
       "      <th>rolling_std_10000</th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.884113333</td>\n",
       "      <td>5.101106131</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>732617.0</td>\n",
       "      <td>5.576566667</td>\n",
       "      <td>4.333324674</td>\n",
       "      <td>104.0</td>\n",
       "      <td>836485.0</td>\n",
       "      <td>2592.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.182269694</td>\n",
       "      <td>4.883418266</td>\n",
       "      <td>4.288590311</td>\n",
       "      <td>4.881665249</td>\n",
       "      <td>4.411259502</td>\n",
       "      <td>4.879250551</td>\n",
       "      <td>4.460670633</td>\n",
       "      <td>4.876886100</td>\n",
       "      <td>4.431413244</td>\n",
       "      <td>1.430797186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.725766667</td>\n",
       "      <td>6.588823782</td>\n",
       "      <td>-154.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>708865.0</td>\n",
       "      <td>5.734166667</td>\n",
       "      <td>5.732776966</td>\n",
       "      <td>181.0</td>\n",
       "      <td>860125.0</td>\n",
       "      <td>11860.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.653421355</td>\n",
       "      <td>4.724876383</td>\n",
       "      <td>4.843485536</td>\n",
       "      <td>4.724689860</td>\n",
       "      <td>5.116232929</td>\n",
       "      <td>4.721938879</td>\n",
       "      <td>5.476469293</td>\n",
       "      <td>4.713898269</td>\n",
       "      <td>6.046480431</td>\n",
       "      <td>1.391498893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.906393333</td>\n",
       "      <td>6.967397034</td>\n",
       "      <td>-106.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>735959.0</td>\n",
       "      <td>6.152646667</td>\n",
       "      <td>5.895944714</td>\n",
       "      <td>140.0</td>\n",
       "      <td>922897.0</td>\n",
       "      <td>129279.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.178792262</td>\n",
       "      <td>4.905839578</td>\n",
       "      <td>5.423012904</td>\n",
       "      <td>4.906173495</td>\n",
       "      <td>5.774157759</td>\n",
       "      <td>4.904014151</td>\n",
       "      <td>6.125550607</td>\n",
       "      <td>4.901086207</td>\n",
       "      <td>6.324556488</td>\n",
       "      <td>1.353196095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.902240000</td>\n",
       "      <td>6.922305187</td>\n",
       "      <td>-199.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>735336.0</td>\n",
       "      <td>5.933960000</td>\n",
       "      <td>6.061213600</td>\n",
       "      <td>199.0</td>\n",
       "      <td>890094.0</td>\n",
       "      <td>67060.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.743548231</td>\n",
       "      <td>4.901486292</td>\n",
       "      <td>4.939280458</td>\n",
       "      <td>4.901312417</td>\n",
       "      <td>5.226714645</td>\n",
       "      <td>4.899401829</td>\n",
       "      <td>5.569334638</td>\n",
       "      <td>4.890118824</td>\n",
       "      <td>6.102269867</td>\n",
       "      <td>1.313797802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.908720000</td>\n",
       "      <td>7.301110190</td>\n",
       "      <td>-126.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>736308.0</td>\n",
       "      <td>6.110586667</td>\n",
       "      <td>6.329485314</td>\n",
       "      <td>145.0</td>\n",
       "      <td>916588.0</td>\n",
       "      <td>80896.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.950485374</td>\n",
       "      <td>4.910195703</td>\n",
       "      <td>5.121868457</td>\n",
       "      <td>4.910102418</td>\n",
       "      <td>5.377340466</td>\n",
       "      <td>4.909516745</td>\n",
       "      <td>5.770087321</td>\n",
       "      <td>4.912307696</td>\n",
       "      <td>6.314026153</td>\n",
       "      <td>1.274399509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4028 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean          std    min    max       sum     abs_mean      abs_std  \\\n",
       "0  4.884113333  5.101106131  -98.0  104.0  732617.0  5.576566667  4.333324674   \n",
       "1  4.725766667  6.588823782 -154.0  181.0  708865.0  5.734166667  5.732776966   \n",
       "2  4.906393333  6.967397034 -106.0  140.0  735959.0  6.152646667  5.895944714   \n",
       "3  4.902240000  6.922305187 -199.0  197.0  735336.0  5.933960000  6.061213600   \n",
       "4  4.908720000  7.301110190 -126.0  145.0  736308.0  6.110586667  6.329485314   \n",
       "\n",
       "   abs_max   abs_sum    argmax  ...  rolling_mean_2000  rolling_mean_4000  \\\n",
       "0    104.0  836485.0    2592.0  ...        4.182269694        4.883418266   \n",
       "1    181.0  860125.0   11860.0  ...        4.653421355        4.724876383   \n",
       "2    140.0  922897.0  129279.0  ...        5.178792262        4.905839578   \n",
       "3    199.0  890094.0   67060.0  ...        4.743548231        4.901486292   \n",
       "4    145.0  916588.0   80896.0  ...        4.950485374        4.910195703   \n",
       "\n",
       "   rolling_mean_10000  rolling_std_100  rolling_std_500  rolling_std_1000  \\\n",
       "0         4.288590311      4.881665249      4.411259502       4.879250551   \n",
       "1         4.843485536      4.724689860      5.116232929       4.721938879   \n",
       "2         5.423012904      4.906173495      5.774157759       4.904014151   \n",
       "3         4.939280458      4.901312417      5.226714645       4.899401829   \n",
       "4         5.121868457      4.910102418      5.377340466       4.909516745   \n",
       "\n",
       "   rolling_std_2000  rolling_std_4000  rolling_std_10000  time_to_failure  \n",
       "0       4.460670633       4.876886100        4.431413244      1.430797186  \n",
       "1       5.476469293       4.713898269        6.046480431      1.391498893  \n",
       "2       6.125550607       4.901086207        6.324556488      1.353196095  \n",
       "3       5.569334638       4.890118824        6.102269867      1.313797802  \n",
       "4       5.770087321       4.912307696        6.314026153      1.274399509  \n",
       "\n",
       "[5 rows x 4028 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if any nan values are generated\n",
    "df_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the data into X_train and Y_train\n",
    "\n",
    "X_train = df_train.drop(columns=['time_to_failure']).values\n",
    "y_train = df_train['time_to_failure'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing the best contributing features using random forest regressor\n",
    "rfr = RandomForestRegressor(n_estimators=500, random_state=0, n_jobs=-1)\n",
    "pipe_rfr = Pipeline([('StandardScaler', StandardScaler()), ('RandomForestRegressor', rfr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('StandardScaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('RandomForestRegressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=6,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling fit on the random forest regressor\n",
    "pipe_rfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe to choose the best features\n",
    "features = pd.DataFrame({'Feature': columns, 'Importance': rfr.feature_importances_, 'Correlation': df_train.drop(columns='time_to_failure').corrwith(df_train['time_to_failure']).abs().values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4016</th>\n",
       "      <td>rolling_mean_500</td>\n",
       "      <td>0.409480064</td>\n",
       "      <td>0.342833017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4018</th>\n",
       "      <td>rolling_mean_2000</td>\n",
       "      <td>0.016739319</td>\n",
       "      <td>0.351513349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abs_std</td>\n",
       "      <td>0.003146086</td>\n",
       "      <td>0.201231156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4020</th>\n",
       "      <td>rolling_mean_10000</td>\n",
       "      <td>0.002197235</td>\n",
       "      <td>0.358516850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4025</th>\n",
       "      <td>rolling_std_4000</td>\n",
       "      <td>0.002072427</td>\n",
       "      <td>0.031354446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Feature   Importance  Correlation\n",
       "4016    rolling_mean_500  0.409480064  0.342833017\n",
       "4018   rolling_mean_2000  0.016739319  0.351513349\n",
       "6                abs_std  0.003146086  0.201231156\n",
       "4020  rolling_mean_10000  0.002197235  0.358516850\n",
       "4025    rolling_std_4000  0.002072427  0.031354446"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorting the features in descending order so we choose the best one\n",
    "features = features.sort_values(by='Importance', ascending=False)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the best performing feature from the 'features' dataframe\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.barh(y='Feature', width='Importance', data=features[:30])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting the top 27 features\n",
    "n_features = 27\n",
    "X_train = df_train[features['Feature'][:n_features]].values\n",
    "y_train = df_train['time_to_failure'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression \n",
    "We started with simple linear regression, since that is the simplest and most straight forward method we are familiar with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare pipeline\n",
    "\n",
    "pipe_linear = Pipeline([('StandardScaler', StandardScaler()), ('Linear', linear_model.LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamters for the linear model\n",
    "\n",
    "parameters_linear = [{\n",
    "    'Linear__fit_intercept': ('True', 'False'),\n",
    "    'Linear__normalize': ('True', 'False'),\n",
    "    'Linear__copy_X': ('True', 'False')\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.3918018972122584\n",
      "Best hyperparameters: {'Linear__copy_X': 'True', 'Linear__fit_intercept': 'True', 'Linear__normalize': 'True'}\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search CV on with different parameters\n",
    "\n",
    "gs_linear = GridSearchCV(\n",
    "    estimator=pipe_linear,\n",
    "    param_grid=parameters_linear,\n",
    "    iid=False,\n",
    "    n_jobs=-1,\n",
    "    cv = KFold(\n",
    "        n_splits=10,\n",
    "        shuffle=True,\n",
    "        random_state=0\n",
    "    )\n",
    ")\n",
    "\n",
    "gs_linear.fit(X_train, y_train)\n",
    "print('Best score:', gs_linear.best_score_)\n",
    "print('Best hyperparameters:', gs_linear.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elastic Net\n",
    "To improve the Linear regression results, we used a penalised method like Elastic search. As we can notice, we got slightly better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare pipeline\n",
    "\n",
    "pipe_elastic = Pipeline([('StandardScaler', StandardScaler()), ('ElasticNet', ElasticNet(random_state=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamters for the elasticnet model\n",
    "\n",
    "param_grid_elastic = [{\n",
    "    'ElasticNet__max_iter': [1, 5, 10],\n",
    "    'ElasticNet__alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'ElasticNet__l1_ratio': np.arange(0.0, 1.0, 0.1)\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.33642312690744053\n",
      "Best hyperparameters: {'ElasticNet__alpha': 0.0001, 'ElasticNet__l1_ratio': 0.9, 'ElasticNet__max_iter': 10}\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search CV on with different parameters\n",
    "gs_elastic = GridSearchCV(\n",
    "    estimator=pipe_elastic,\n",
    "    param_grid=param_grid_elastic,\n",
    "    iid=False,\n",
    "    n_jobs=-1,\n",
    "    cv = KFold(\n",
    "        n_splits=10,\n",
    "        shuffle=True,\n",
    "        random_state=0\n",
    "    )\n",
    ")\n",
    "\n",
    "gs_elastic.fit(X_train, y_train)\n",
    "print('Best score:', gs_elastic.best_score_)\n",
    "print('Best hyperparameters:', gs_elastic.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next model we are trying is neural network. Earthquakes are a complicated phenomenon, so we expect a neural network to be better at capturing the non-linearity and perform better than linear regression.\n",
    "\n",
    "We are using the top 27 features ranked by importance, so we search through a grid of different hidden layer numbers and sizes. The other hyperparameters being tuned are the learning rate, regularization parameter and the tolerance for cross validation score stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Pipeline\n",
    "\n",
    "pipe_nn = Pipeline([('StandardScaler', StandardScaler()), ('Regressor', MLPRegressor(random_state=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamters for the neural network model\n",
    "\n",
    "param_grid_nn = [{\n",
    "    'Regressor__hidden_layer_sizes': [(18), (18, 12), (18, 12, 8)],\n",
    "    'Regressor__alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'Regressor__learning_rate_init': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'Regressor__tol': [0.0001, 0.001, 0.01]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.4384087789719068\n",
      "Best hyperparameters: {'Regressor__alpha': 0.01, 'Regressor__hidden_layer_sizes': 18, 'Regressor__learning_rate_init': 0.1, 'Regressor__tol': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search CV on with different parameters\n",
    "\n",
    "gs_nn = GridSearchCV(\n",
    "    estimator=pipe_nn,\n",
    "    param_grid=param_grid_nn,\n",
    "    iid=False,\n",
    "    n_jobs=-1,\n",
    "    cv = KFold(\n",
    "        n_splits=10,\n",
    "        shuffle=True,\n",
    "        random_state=0\n",
    "    )\n",
    ")\n",
    "\n",
    "gs_nn.fit(X_train, y_train)\n",
    "print('Best score:', gs_nn.best_score_)\n",
    "print('Best hyperparameters:', gs_nn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traverse through the test directory\n",
    "path = 'data/test/'\n",
    "files = [f[:-4] for f in listdir(path) if isfile(path + f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a submission dataframe\n",
    "\n",
    "predictions = pd.DataFrame(index=files, dtype=np.float, columns=['time_to_failure'])\n",
    "predictions.index.name = 'seg_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all files in the test folder, run predict function and add to 'predictions' dataframe\n",
    "\n",
    "for f in files:\n",
    "    df = pd.read_csv(path+f+'.csv')\n",
    "    df_test = pd.DataFrame(np.array(generate_features(df)).reshape(1,-1), columns=columns)\n",
    "    X_test = df_test[features['Feature'][:n_features]].values\n",
    "    y = gs_nn.predict(X_test)[0]\n",
    "    predictions.loc[f, 'time_to_failure'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>seg_5fe414</th>\n",
       "      <td>2.695770116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_3661de</th>\n",
       "      <td>9.861931215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_5ef47e</th>\n",
       "      <td>5.391954501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_58e9f9</th>\n",
       "      <td>8.253845824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_afd665</th>\n",
       "      <td>4.431446236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            time_to_failure\n",
       "seg_id                     \n",
       "seg_5fe414      2.695770116\n",
       "seg_3661de      9.861931215\n",
       "seg_5ef47e      5.391954501\n",
       "seg_58e9f9      8.253845824\n",
       "seg_afd665      4.431446236"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peek at the predictions\n",
    "\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the predictions dataframe to a csv\n",
    "\n",
    "predictions.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network using tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function returning a compiled network\n",
    "def kerasModel(optimizer, metrics, loss, activation, input_shape= X_train.shape[1]):\n",
    "    \n",
    "    # Start neural network\n",
    "    network = models.Sequential()\n",
    "\n",
    "    # Add fully connected layer with a ReLU activation function\n",
    "    network.add(layers.Dense(units=input_shape, activation=activation, input_dim=input_shape))\n",
    "\n",
    "    # Add fully connected layer with a ReLU activation function\n",
    "    network.add(layers.Dense(units= int(input_shape/2), activation=activation))\n",
    "\n",
    "    # Add fully connected layer with a sigmoid activation function\n",
    "    network.add(layers.Dense(units=1))\n",
    "\n",
    "    # Compile neural network\n",
    "    network.compile(loss=loss, # Cross-entropy\n",
    "                    optimizer=optimizer, # Optimizer\n",
    "                    metrics=[metrics]) # Accuracy performance metric\n",
    "    \n",
    "    # Return compiled network\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "KModel = KerasRegressor(build_fn=kerasModel, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hyperparameter space\n",
    "epochs = [50 , 100]\n",
    "batches = [50, 100]\n",
    "optimizer = ['adam','sgd']\n",
    "loss = ['mse','mae']\n",
    "activation = ['relu', 'exponential']\n",
    "metrics = ['mse','mae']\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(Model__optimizer=optimizer, Model__loss = loss, Model__epochs=epochs, Model__batch_size=batches, Model__activation= activation,\n",
    "                            Model__metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_keras = Pipeline([('StandardScaler', StandardScaler()), ('Model', KModel)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -2.1220072840666115\n",
      "Best hyperparameters: {'Model__activation': 'relu', 'Model__batch_size': 100, 'Model__epochs': 100, 'Model__loss': 'mae', 'Model__metrics': 'mae', 'Model__optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "gs_keras = GridSearchCV(\n",
    "    estimator=pipe_keras,\n",
    "    param_grid=hyperparameters,\n",
    "    iid = False,\n",
    "    n_jobs=-1,\n",
    "    cv = KFold(\n",
    "        n_splits=10,\n",
    "        shuffle=True,\n",
    "        random_state=0\n",
    "    )\n",
    ")\n",
    "\n",
    "gs_keras.fit(X_train, y_train)\n",
    "print('Best score:', gs_keras.best_score_)\n",
    "print('Best hyperparameters:', gs_keras.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a predictions empty dataframe to use later on\n",
    "\n",
    "predictions_Keras = pd.DataFrame(index=files, dtype=np.float, columns=['time_to_failure'])\n",
    "predictions_Keras.index.name = 'seg_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all files in the test folder, run predict function and add to 'predictions' dataframe\n",
    "\n",
    "for f in files:\n",
    "    df = pd.read_csv(path+f+'.csv')\n",
    "    df_test = pd.DataFrame(np.array(generate_features(df)).reshape(1,-1), columns=columns)\n",
    "    X_test = df_test[features['Feature'][:n_features]].values\n",
    "    y = gs_nn.predict(X_test)[0]\n",
    "    predictions_Keras.loc[f, 'time_to_failure'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>seg_5fe414</th>\n",
       "      <td>2.695770116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_3661de</th>\n",
       "      <td>9.861931215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_5ef47e</th>\n",
       "      <td>5.391954501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_58e9f9</th>\n",
       "      <td>8.253845824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_afd665</th>\n",
       "      <td>4.431446236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            time_to_failure\n",
       "seg_id                     \n",
       "seg_5fe414      2.695770116\n",
       "seg_3661de      9.861931215\n",
       "seg_5ef47e      5.391954501\n",
       "seg_58e9f9      8.253845824\n",
       "seg_afd665      4.431446236"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peek at the predictions\n",
    "\n",
    "predictions_Keras.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the predictions dataframe to a csv\n",
    "\n",
    "predictions_Keras.to_csv('submission_Keras.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the cross validation score, we expect Neural Network with 1 input layer, 1 hidden layer with 18 nodes and 1 output layer to give us the best R<sup>2</sup> coefficient. \n",
    "\n",
    "Another important observation we can make in this experiment is that, the performance of the model is higly correlated with the features used. As we can see in the graph, rolling_mean_500 has an importance value of 0.41, followed by  rolling_mean_2000 with an importance value of 0.01. We can see a strike difference in the performance of the features.\n",
    "\n",
    "In conclusion, Neural Network is the best model for this data. More importantly, efficient feature engineering is the key to building a good model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- https://kaggle.com/c/LANL-Earthquake-Prediction/discussion\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\n",
    "- https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
